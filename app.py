# -*- coding: utf-8 -*-
import io
import time
import shutil
import tempfile
from datetime import datetime

import streamlit as st
from openpyxl import Workbook
from openpyxl.styles import Font, Alignment
from openpyxl.utils import get_column_letter

from pdf_contracts import (
    HEADERS,
    parse_contract,
    extract_raw_and_normalized_text,
    calc_quality,
)

APP_TITLE = "ğŸ“„ ØªØ­ÙˆÙŠÙ„ Ø¹Ù‚ÙˆØ¯ PDF Ø¥Ù„Ù‰ Excel (Ù‚ÙˆÙŠ + ØªÙ‚Ø±ÙŠØ±)"
OUTPUT_FILE_NAME = "Employees_Data.xlsx"
SHEET_MAIN = "Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†"
SHEET_LOGS = "Logs"

st.set_page_config(page_title="PDF â†’ Excel (Ø¹Ù‚ÙˆØ¯ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†)", page_icon="ğŸ“„", layout="wide")
st.title(APP_TITLE)

st.write(
    "Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª PDF (Ø£ÙŠ Ø¹Ø¯Ø¯). ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙˆØ¶Ø¹ ÙƒÙ„ Ù…ÙˆØ¸Ù ÙÙŠ Ø³Ø·Ø± ÙˆØ§Ø­Ø¯ Ø¯Ø§Ø®Ù„ Excel.\n"
    "Ø£ÙŠ Ø­Ù‚Ù„ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¹Ù‚Ø¯ Ø³ÙŠØ¨Ù‚Ù‰ ÙØ§Ø±Øº. ÙˆØ¥Ø°Ø§ Ù…Ù„Ù ÙˆØ§Ø­Ø¯ ÙÙŠÙ‡ Ù…Ø´ÙƒÙ„Ø©ØŒ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© ØªÙƒÙ…Ù„ Ù„Ù„Ø¨Ø§Ù‚ÙŠ."
)

with st.expander("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª", expanded=False):
    c1, c2, c3, c4 = st.columns(4)
    with c1:
        include_logs_sheet = st.checkbox("Ø¥Ø¶Ø§ÙØ© ÙˆØ±Ù‚Ø© Logs ÙÙŠ Excel", value=True)
    with c2:
        enable_debug = st.checkbox("Debug: Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù… + Ø¨Ø¹Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠØ¹", value=True)
    with c3:
        show_quality_table = st.checkbox("Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬", value=True)
    with c4:
        cleanup_delay = st.slider("Ø«ÙˆØ§Ù†ÙŠ Ù‚Ø¨Ù„ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©", 0, 8, 2)

uploaded = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª PDF Ù‡Ù†Ø§", type=["pdf"], accept_multiple_files=True)

def _auto_width(ws, max_width=70, min_width=10):
    for col_idx in range(1, ws.max_column + 1):
        header = ws.cell(row=1, column=col_idx).value or ""
        max_len = len(str(header))
        for r in range(2, ws.max_row + 1):
            v = ws.cell(row=r, column=col_idx).value
            if v is None:
                continue
            max_len = max(max_len, len(str(v)))
        ws.column_dimensions[get_column_letter(col_idx)].width = min(max(min_width, max_len + 2), max_width)

def build_excel_bytes(rows, logs=None, include_logs=True):
    wb = Workbook()
    ws = wb.active
    ws.title = SHEET_MAIN

    ws.append(HEADERS)
    for c in range(1, len(HEADERS) + 1):
        cell = ws.cell(row=1, column=c)
        cell.font = Font(bold=True)
        cell.alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)

    for row in rows:
        ws.append([row.get(h, "") if row.get(h, "") is not None else "" for h in HEADERS])

    ws.freeze_panes = "A2"
    for row_cells in ws.iter_rows(min_row=2, max_row=ws.max_row, max_col=len(HEADERS)):
        for cell in row_cells:
            cell.alignment = Alignment(vertical="top", wrap_text=True)

    _auto_width(ws)

    if include_logs:
        ws2 = wb.create_sheet(SHEET_LOGS)
        ws2.append([
            "timestamp", "file_name", "status",
            "filled_fields", "total_fields", "quality_%", "missing_fields",
            "note"
        ])
        for c in range(1, 9):
            cell = ws2.cell(row=1, column=c)
            cell.font = Font(bold=True)
            cell.alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)

        if logs:
            for item in logs:
                ws2.append([
                    item.get("timestamp",""),
                    item.get("file_name",""),
                    item.get("status",""),
                    item.get("filled_fields",""),
                    item.get("total_fields",""),
                    item.get("quality_pct",""),
                    item.get("missing_fields",""),
                    item.get("note",""),
                ])

        ws2.freeze_panes = "A2"
        for row_cells in ws2.iter_rows(min_row=2, max_row=ws2.max_row, max_col=8):
            for cell in row_cells:
                cell.alignment = Alignment(vertical="top", wrap_text=True)

        _auto_width(ws2, max_width=90)

    bio = io.BytesIO()
    wb.save(bio)
    bio.seek(0)
    return bio.getvalue()

def safe_lines(s: str, n=120) -> str:
    if not s:
        return ""
    return "\n".join(s.splitlines()[:n])

def process_files(files):
    rows = []
    logs = []
    debug_items = []
    report_lines = []

    total_files = len(files)
    progress = st.progress(0)
    status = st.empty()

    for i, f in enumerate(files, start=1):
        status.write(f"Ø¬Ø§Ø±Ù Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù {i}/{total_files}: **{f.name}**")
        ts = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")

        try:
            pdf_bytes = f.read()
            if not pdf_bytes or len(pdf_bytes) < 50:
                row = {h: "" for h in HEADERS}
                filled, total, pct, missing = calc_quality(row)

                rows.append(row)
                logs.append({
                    "timestamp": ts,
                    "file_name": f.name,
                    "status": "SKIPPED",
                    "filled_fields": filled,
                    "total_fields": total,
                    "quality_pct": pct,
                    "missing_fields": ", ".join(missing[:10]) + (" ..." if len(missing) > 10 else ""),
                    "note": "File empty/too small"
                })

                report_lines.append(f"- {f.name}: SKIPPED (empty)")
                debug_items.append({"file": f.name, "raw": "", "norm": "", "note": "empty"})
            else:
                raw_text, norm_text = extract_raw_and_normalized_text(pdf_bytes)
                data = parse_contract(norm_text) or {}
                row = {h: (data.get(h, "") if data.get(h, "") is not None else "") for h in HEADERS}

                filled, total, pct, missing = calc_quality(row)

                status_label = "OK" if pct >= 35 else "LOW_QUALITY"
                note = "Parsed successfully" if status_label == "OK" else "Low filled fields; check Debug text"

                rows.append(row)
                logs.append({
                    "timestamp": ts,
                    "file_name": f.name,
                    "status": status_label,
                    "filled_fields": filled,
                    "total_fields": total,
                    "quality_pct": pct,
                    "missing_fields": ", ".join(missing[:10]) + (" ..." if len(missing) > 10 else ""),
                    "note": note
                })

                report_lines.append(f"- {f.name}: {status_label} | Quality {pct}% | Missing {len(missing)} fields")

                if enable_debug:
                    debug_items.append({
                        "file": f.name,
                        "raw": safe_lines(raw_text, 80),
                        "norm": safe_lines(norm_text, 120),
                        "note": f"Quality {pct}%"
                    })

        except Exception as e:
            row = {h: "" for h in HEADERS}
            filled, total, pct, missing = calc_quality(row)

            rows.append(row)
            logs.append({
                "timestamp": ts,
                "file_name": f.name,
                "status": "ERROR",
                "filled_fields": filled,
                "total_fields": total,
                "quality_pct": pct,
                "missing_fields": ", ".join(missing[:10]) + (" ..." if len(missing) > 10 else ""),
                "note": f"{type(e).__name__}: {str(e)}"
            })
            report_lines.append(f"- {f.name}: ERROR -> {type(e).__name__}: {str(e)}")
            debug_items.append({"file": f.name, "raw": "", "norm": "", "note": f"ERROR: {e}"})

        progress.progress(int(i / total_files * 100))

    status.write("âœ… Ø§Ù†ØªÙ‡Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©.")
    report_text = "PDF Contracts Extraction Report\n" + "\n".join(report_lines)
    return rows, logs, debug_items, report_text

if uploaded:
    st.info(f"Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©: **{len(uploaded)}**")
    run = st.button("âš™ï¸ ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Excel", type="primary")
else:
    run = False

if run:
    temp_dir = tempfile.mkdtemp(prefix="pdf_to_excel_")
    try:
        rows, logs, debug_items, report_text = process_files(uploaded)

        if show_quality_table:
            st.subheader("ğŸ“Š Ø¬ÙˆØ¯Ø© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÙƒÙ„ Ù…Ù„Ù")
            for item in logs:
                st.write(
                    f"- **{item['file_name']}** | Status: `{item['status']}` | "
                    f"Filled: {item['filled_fields']}/{item['total_fields']} | "
                    f"Quality: **{item['quality_pct']}%** | Missing: {item['missing_fields']}"
                )

        excel_bytes = build_excel_bytes(rows, logs=logs, include_logs=include_logs_sheet)

        st.success("âœ… ØªÙ… ØªØ¬Ù‡ÙŠØ² Ù…Ù„Ù Excel Ø¨Ù†Ø¬Ø§Ø­!")
        st.download_button(
            label="â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Employees_Data.xlsx",
            data=excel_bytes,
            file_name=OUTPUT_FILE_NAME,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

        st.download_button(
            label="â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„ (TXT)",
            data=report_text.encode("utf-8"),
            file_name="Extraction_Report.txt",
            mime="text/plain",
        )

        if enable_debug:
            st.subheader("ğŸ§ª Debug Ù„ÙƒÙ„ Ù…Ù„Ù (Ø®Ø§Ù… + Ø¨Ø¹Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠØ¹)")
            st.caption("Ù„Ùˆ Ø­Ù‚Ù„ Ù…Ø§ ÙŠØ·Ù„Ø¹ØŒ Ø§ÙØªØ­ Ø§Ù„Ù…Ù„Ù ÙˆØ´ÙˆÙ Ø§Ù„Ù†Øµ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠØ¹ â€” Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ù„ÙŠ Ù†Ø¹ØªÙ…Ø¯ Ø¹Ù„ÙŠÙ‡ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬.")
            for d in debug_items:
                with st.expander(f"ğŸ“„ {d['file']} â€” {d['note']}", expanded=False):
                    st.text_area("RAW (first 80 lines)", d.get("raw",""), height=210)
                    st.text_area("NORMALIZED (first 120 lines)", d.get("norm",""), height=260)

        st.info("ğŸ§¹ Ø³ÙŠØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ© ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§.")
        time.sleep(int(cleanup_delay))

    finally:
        shutil.rmtree(temp_dir, ignore_errors=True)
